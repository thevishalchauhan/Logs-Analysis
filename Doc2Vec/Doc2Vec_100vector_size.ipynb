{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "# tqdm is for printing the status bar\n",
    "def textpreprocess(sentance):\n",
    "    #remove words with numbers python: https://stackoverflow.com/a/18082370/4084039\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", str(sentance)).strip()\n",
    "    #remove spacial character: https://stackoverflow.com/a/5843547/4084039\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "    #remove stop words\n",
    "    sentance = [e.lower() for e in sentance.split() if e.lower() not in stoplist]\n",
    "    return sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['mlu', 'e', 'status', 'device', 'ready', 'n',...</td>\n",
       "      <td>DeviceNotReady_BelowMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['deferred', 'odntodo', 'odnwip', 'n', 'mlu', ...</td>\n",
       "      <td>DeviceNotReady_BelowMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['user', 'kdriver', 'starting', 'input', 'powe...</td>\n",
       "      <td>DeviceNotReady_BelowMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['mlu', 'mlu', 'adding', 'waiter', 'obj', 'run...</td>\n",
       "      <td>DeviceNotReady_BelowMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['user', 'tldlistener', 'start', 'operation', ...</td>\n",
       "      <td>MCC_BadCRC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Log_Data                   Label\n",
       "0  ['mlu', 'e', 'status', 'device', 'ready', 'n',...  DeviceNotReady_BelowMR\n",
       "1  ['deferred', 'odntodo', 'odnwip', 'n', 'mlu', ...  DeviceNotReady_BelowMR\n",
       "2  ['user', 'kdriver', 'starting', 'input', 'powe...  DeviceNotReady_BelowMR\n",
       "3  ['mlu', 'mlu', 'adding', 'waiter', 'obj', 'run...  DeviceNotReady_BelowMR\n",
       "4  ['user', 'tldlistener', 'start', 'operation', ...              MCC_BadCRC"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_logs_preprocessed.csv', usecols = [1,2])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.Log_Data, df.Label, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v, [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load(\"Doc2VecModel\\d2v_100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec with vector size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model, len(X_train), 100, 'Train')\n",
    "test_vectors_dbow = get_vectors(model, len(X_test), 100, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49241304,  0.70340157,  0.23149845, -0.02682587, -0.61650205,\n",
       "         0.81051832,  0.50213176,  0.06146568,  1.23969436,  0.199426  ,\n",
       "         0.22975758, -0.31902048,  0.39385557,  0.05008138,  0.30576807,\n",
       "         0.1927543 ,  0.70859492,  0.71159929,  0.19086701, -0.53068882,\n",
       "         0.39757791,  0.12827803, -0.08500989, -0.05976348,  0.26870283,\n",
       "         0.33567947, -0.18176225, -0.24827673,  0.03558635,  0.41958907,\n",
       "         0.52064794, -0.68858832, -0.57401502,  0.2581695 ,  0.91493905,\n",
       "        -0.18037879,  0.32701004, -0.47905803, -0.02605346,  0.67185003,\n",
       "         0.87475747, -0.70954102,  0.32525584,  0.31076735, -0.05028684,\n",
       "         0.31179842, -0.62463552, -0.21509029,  0.26035225, -0.06583729,\n",
       "         0.54485279,  0.18495038, -0.08383705,  0.38938448,  0.6713354 ,\n",
       "         0.0059522 , -0.07335039, -0.04556746, -0.2041374 , -0.17144188,\n",
       "         0.05500981,  0.56692076, -0.63429248,  0.379159  ,  0.28479728,\n",
       "        -0.24035667, -0.19270813,  0.33784208, -0.73197246, -0.17442806,\n",
       "         0.44945806, -0.8431291 , -0.02845616,  0.4274852 ,  0.28483313,\n",
       "         0.3823134 ,  0.19554844,  0.43197078, -0.29742914, -0.06006983,\n",
       "        -0.65628338, -0.72935581,  0.21806735,  0.47816142, -0.59868383,\n",
       "        -0.79573041,  0.01315622,  0.17742236, -0.52072442,  0.34141108,\n",
       "         0.4804343 , -0.23830469,  0.08099956, -0.00268533, -0.10617194,\n",
       "         0.60087222,  0.0838576 ,  0.32253927,  0.36940953, -0.13893992],\n",
       "       [-0.09343717,  0.16696507,  0.22879653,  0.21453002, -0.18556701,\n",
       "         1.21351409, -0.162699  ,  0.12900503,  0.41567513, -0.02616603,\n",
       "         0.31445515, -0.46949843, -0.24586353,  0.71460038,  0.33787933,\n",
       "         0.74333376,  0.45020995,  0.27371573,  0.34221628, -0.1097949 ,\n",
       "        -0.23718353,  0.07950483, -0.02501399, -0.12653868,  0.00541178,\n",
       "         0.63283074, -0.03874759, -0.31496888, -0.14577614, -0.13279034,\n",
       "         0.16502126,  0.09030052, -0.51495457,  0.48869219,  0.65412837,\n",
       "        -0.57524467, -0.5574677 , -0.16245545, -0.09877821,  0.77467376,\n",
       "        -0.13246858, -0.31144264, -0.62628996,  0.80978155, -0.14627694,\n",
       "         0.89913821, -0.34834182, -0.06004216,  0.07976329, -0.13634734,\n",
       "         0.16272946,  0.17203166, -0.38729513, -0.65469968,  0.75074893,\n",
       "        -0.05244118, -0.57600516,  0.5082798 ,  0.44530401,  0.45349035,\n",
       "         0.24380976,  0.06263394,  0.02541951,  0.26970416,  0.33235478,\n",
       "        -0.35833949,  0.09591521,  0.17200193,  0.02393681, -0.48887905,\n",
       "         0.07809975, -0.39462438,  0.44822687,  0.23458314, -0.66677606,\n",
       "        -0.1315234 ,  0.20837076, -0.13957947, -0.12724508,  0.47000742,\n",
       "        -0.20106368, -0.8828994 , -0.11811417, -0.03703425, -0.29640359,\n",
       "         0.29237092, -0.42086092,  0.27942094,  0.34751981,  0.48765126,\n",
       "        -0.00333557,  0.19530389,  0.44088596,  0.0402315 ,  0.59301007,\n",
       "         0.4912363 ,  0.44219932,  0.43311694,  0.07015594, -0.29759192]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors_dbow[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression ( 91.6% Accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "         DeviceNotReady_BelowMR       0.00      0.00      0.00         1\n",
      "Weka_Collects_Miniport_Slowness       0.67      1.00      0.80         2\n",
      "                     MCC_BadCRC       1.00      1.00      1.00         2\n",
      "                  MCC_CacheLost       1.00      1.00      1.00         2\n",
      "                            MCR       1.00      1.00      1.00         3\n",
      "                raid_data_error       1.00      1.00      1.00         2\n",
      "\n",
      "                      micro avg       0.92      0.92      0.92        12\n",
      "                      macro avg       0.78      0.83      0.80        12\n",
      "                   weighted avg       0.86      0.92      0.88        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=list(set(df.Label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Y_test            Y_pred\n",
      "------------------------\n",
      "MCR  ==  MCR\n",
      "MCR  ==  MCR\n",
      "MCC_CacheLost  ==  MCC_CacheLost\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n",
      "raid_data_error  ==  raid_data_error\n",
      "MCC_CacheLost  ==  MCC_CacheLost\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "!!!! DeviceNotReady_BelowMR  !=  MCC_BadCRC\n",
      "raid_data_error  ==  raid_data_error\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------\")\n",
    "print(\"Y_test            Y_pred\")\n",
    "print(\"------------------------\")\n",
    "for i,j in zip(y_test,y_pred):\n",
    "    if i == j:\n",
    "        print(i+\"  ==  \"+j)\n",
    "    else:\n",
    "        print(\"!!!! \"+i+\"  !=  \"+j)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent (83.3% Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "         DeviceNotReady_BelowMR       0.00      0.00      0.00         1\n",
      "Weka_Collects_Miniport_Slowness       0.67      1.00      0.80         2\n",
      "                     MCC_BadCRC       1.00      0.50      0.67         2\n",
      "                  MCC_CacheLost       1.00      1.00      1.00         2\n",
      "                            MCR       1.00      1.00      1.00         3\n",
      "                raid_data_error       0.67      1.00      0.80         2\n",
      "\n",
      "                      micro avg       0.83      0.83      0.83        12\n",
      "                      macro avg       0.72      0.75      0.71        12\n",
      "                   weighted avg       0.81      0.83      0.79        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(max_iter=100, tol=1e-3, random_state = 101)\n",
    "sgd.fit(train_vectors_dbow, y_train)\n",
    "y_pred_sgd = sgd.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred_sgd, y_test))\n",
    "print(classification_report(y_test, y_pred_sgd,target_names=list(set(df.Label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Y_test            Y_pred\n",
      "------------------------\n",
      "MCR  ==  MCR\n",
      "MCR  ==  MCR\n",
      "MCC_CacheLost  ==  MCC_CacheLost\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n",
      "raid_data_error  ==  raid_data_error\n",
      "!!! MCC_CacheLost  !=  raid_data_error\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "!!! DeviceNotReady_BelowMR  !=  MCC_BadCRC\n",
      "raid_data_error  ==  raid_data_error\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------\")\n",
    "print(\"Y_test            Y_pred\")\n",
    "print(\"------------------------\")\n",
    "for i,j in zip(y_test,y_pred_sgd):\n",
    "    if i == j:\n",
    "        print(i+\"  ==  \"+j)\n",
    "    else:\n",
    "        print(\"!!! \"+i+\"  !=  \"+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours (83.3% Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8333333333333334\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "         DeviceNotReady_BelowMR       0.00      0.00      0.00         1\n",
      "Weka_Collects_Miniport_Slowness       0.50      0.50      0.50         2\n",
      "                     MCC_BadCRC       1.00      1.00      1.00         2\n",
      "                  MCC_CacheLost       1.00      1.00      1.00         2\n",
      "                            MCR       1.00      1.00      1.00         3\n",
      "                raid_data_error       1.00      1.00      1.00         2\n",
      "\n",
      "                      micro avg       0.83      0.83      0.83        12\n",
      "                      macro avg       0.75      0.75      0.75        12\n",
      "                   weighted avg       0.83      0.83      0.83        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=len(set(df.Label)))\n",
    "neigh.fit(train_vectors_dbow, y_train)\n",
    "y_pred_neigh = neigh.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred_neigh, y_test))\n",
    "print(classification_report(y_test, y_pred_neigh,target_names=list(set(df.Label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Y_test            Y_pred\n",
      "------------------------\n",
      "MCR  ==  MCR\n",
      "MCR  ==  MCR\n",
      "MCC_CacheLost  ==  MCC_CacheLost\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n",
      "raid_data_error  ==  raid_data_error\n",
      "MCC_CacheLost  ==  MCC_CacheLost\n",
      "!!!! MCC_BadCRC  !=  DeviceNotReady_BelowMR\n",
      "!!!! DeviceNotReady_BelowMR  !=  MCC_BadCRC\n",
      "raid_data_error  ==  raid_data_error\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------\")\n",
    "print(\"Y_test            Y_pred\")\n",
    "print(\"------------------------\")\n",
    "for i,j in zip(y_test,y_pred_neigh):\n",
    "    if i == j:\n",
    "        print(i+\"  ==  \"+j)\n",
    "    else:\n",
    "        print(\"!!!! \"+i+\"  !=  \"+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier (50% Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "         DeviceNotReady_BelowMR       0.50      1.00      0.67         1\n",
      "Weka_Collects_Miniport_Slowness       0.67      1.00      0.80         2\n",
      "                     MCC_BadCRC       0.33      0.50      0.40         2\n",
      "                  MCC_CacheLost       0.00      0.00      0.00         2\n",
      "                            MCR       0.00      0.00      0.00         3\n",
      "                raid_data_error       0.50      1.00      0.67         2\n",
      "\n",
      "                      micro avg       0.50      0.50      0.50        12\n",
      "                      macro avg       0.33      0.58      0.42        12\n",
      "                   weighted avg       0.29      0.50      0.37        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(random_state=101, max_features = None, max_depth = 10, min_samples_leaf = 4)\n",
    "dtree.fit(train_vectors_dbow, y_train)\n",
    "y_pred_dtree = dtree.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred_dtree, y_test))\n",
    "print(classification_report(y_test, y_pred_dtree,target_names=list(set(df.Label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Y_test            Y_pred\n",
      "------------------------\n",
      "!!!! MCR  !=  raid_data_error\n",
      "!!!! MCR  !=  MCC_CacheLost\n",
      "!!!! MCC_CacheLost  !=  raid_data_error\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "!!!! Weka_Collects_Miniport_Slowness  !=  MCC_CacheLost\n",
      "raid_data_error  ==  raid_data_error\n",
      "MCC_CacheLost  ==  MCC_CacheLost\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "DeviceNotReady_BelowMR  ==  DeviceNotReady_BelowMR\n",
      "raid_data_error  ==  raid_data_error\n",
      "!!!! Weka_Collects_Miniport_Slowness  !=  MCC_BadCRC\n",
      "!!!! Weka_Collects_Miniport_Slowness  !=  DeviceNotReady_BelowMR\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------\")\n",
    "print(\"Y_test            Y_pred\")\n",
    "print(\"------------------------\")\n",
    "for i,j in zip(y_test,y_pred_dtree):\n",
    "    if i == j:\n",
    "        print(i+\"  ==  \"+j)\n",
    "    else:\n",
    "        print(\"!!!! \"+i+\"  !=  \"+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (50% Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "         DeviceNotReady_BelowMR       0.50      1.00      0.67         1\n",
      "Weka_Collects_Miniport_Slowness       0.67      1.00      0.80         2\n",
      "                     MCC_BadCRC       0.33      0.50      0.40         2\n",
      "                  MCC_CacheLost       0.00      0.00      0.00         2\n",
      "                            MCR       0.00      0.00      0.00         3\n",
      "                raid_data_error       0.50      1.00      0.67         2\n",
      "\n",
      "                      micro avg       0.50      0.50      0.50        12\n",
      "                      macro avg       0.33      0.58      0.42        12\n",
      "                   weighted avg       0.29      0.50      0.37        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfm = RandomForestClassifier(n_estimators=100, max_depth=10,random_state=101, oob_score = True, max_features = None,\n",
    "                             min_samples_leaf = 4, n_jobs = -1)\n",
    "rfm.fit(train_vectors_dbow, y_train)\n",
    "y_pred_rfm = dtree.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred_rfm, y_test))\n",
    "print(classification_report(y_test, y_pred_rfm,target_names=list(set(df.Label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Y_test            Y_pred\n",
      "------------------------\n",
      "!!!! MCR  !=  raid_data_error\n",
      "!!!! MCR  !=  MCC_CacheLost\n",
      "!!!! MCC_CacheLost  !=  raid_data_error\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "!!!! Weka_Collects_Miniport_Slowness  !=  MCC_CacheLost\n",
      "raid_data_error  ==  raid_data_error\n",
      "MCC_CacheLost  ==  MCC_CacheLost\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "DeviceNotReady_BelowMR  ==  DeviceNotReady_BelowMR\n",
      "raid_data_error  ==  raid_data_error\n",
      "!!!! Weka_Collects_Miniport_Slowness  !=  MCC_BadCRC\n",
      "!!!! Weka_Collects_Miniport_Slowness  !=  DeviceNotReady_BelowMR\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------\")\n",
    "print(\"Y_test            Y_pred\")\n",
    "print(\"------------------------\")\n",
    "for i,j in zip(y_test,y_pred_rfm):\n",
    "    if i == j:\n",
    "        print(i+\"  ==  \"+j)\n",
    "    else:\n",
    "        print(\"!!!! \"+i+\"  !=  \"+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (91.6 %  Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "         DeviceNotReady_BelowMR       0.00      0.00      0.00         1\n",
      "Weka_Collects_Miniport_Slowness       0.67      1.00      0.80         2\n",
      "                     MCC_BadCRC       1.00      1.00      1.00         2\n",
      "                  MCC_CacheLost       1.00      1.00      1.00         2\n",
      "                            MCR       1.00      1.00      1.00         3\n",
      "                raid_data_error       1.00      1.00      1.00         2\n",
      "\n",
      "                      micro avg       0.92      0.92      0.92        12\n",
      "                      macro avg       0.78      0.83      0.80        12\n",
      "                   weighted avg       0.86      0.92      0.88        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', random_state = 101, C = 1)\n",
    "svm.fit(train_vectors_dbow, y_train)\n",
    "y_pred_svm = svm.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred_svm, y_test))\n",
    "print(classification_report(y_test, y_pred_svm,target_names=list(set(df.Label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Y_test            Y_pred\n",
      "------------------------\n",
      "MCR  ==  MCR\n",
      "MCR  ==  MCR\n",
      "MCC_CacheLost  ==  MCC_CacheLost\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n",
      "raid_data_error  ==  raid_data_error\n",
      "MCC_CacheLost  ==  MCC_CacheLost\n",
      "MCC_BadCRC  ==  MCC_BadCRC\n",
      "!!!! DeviceNotReady_BelowMR  !=  MCC_BadCRC\n",
      "raid_data_error  ==  raid_data_error\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n",
      "Weka_Collects_Miniport_Slowness  ==  Weka_Collects_Miniport_Slowness\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------\")\n",
    "print(\"Y_test            Y_pred\")\n",
    "print(\"------------------------\")\n",
    "for i,j in zip(y_test,y_pred_svm):\n",
    "    if i == j:\n",
    "        print(i+\"  ==  \"+j)\n",
    "    else:\n",
    "        print(\"!!!! \"+i+\"  !=  \"+j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
